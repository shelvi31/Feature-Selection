{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "diagnostic-ocean",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION USING FILTER METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-hypothetical",
   "metadata": {},
   "source": [
    "### What is Feature Selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-hello",
   "metadata": {},
   "source": [
    "Feature selection, also known as variable/predictor selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features for use in machine learning model construction.\n",
    "\n",
    "Machine learning works on a simple rule – if you put garbage in, you will only get garbage to come out. By garbage here, I mean noise in data.\n",
    "\n",
    "This becomes even more important when the number of features is very large. You need not use every feature at your disposal for creating an algorithm. You can assist your algorithm by feeding in only those features that are really important. “Sometimes, less is better!”\n",
    "\n",
    "You not only reduce the training time and the evaluation time, but you also have fewer things to worry about!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-austin",
   "metadata": {},
   "source": [
    "### Feature engineering vs Feature selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-rider",
   "metadata": {},
   "source": [
    "Feature engineering enables you to build more complex models than you could with only raw data. It also allows you to build interpretable models from any amount of data. Feature selection will help you limit these features to a manageable number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-handling",
   "metadata": {},
   "source": [
    "### Feature selection vs Feature extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-tokyo",
   "metadata": {},
   "source": [
    "Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-stake",
   "metadata": {},
   "source": [
    "### Importance of Feature Selection in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-purple",
   "metadata": {},
   "source": [
    "There are 2 things that distinguish data science winners from others in most cases: Feature Creation and Feature Selection.\n",
    "\n",
    "In other words, it boils down to creating variables that capture hidden business insights and then making the right choices about which variable to choose for your predictive models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-istanbul",
   "metadata": {},
   "source": [
    "### The top reasons to use feature selection are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-enterprise",
   "metadata": {},
   "source": [
    "- It enables the machine learning algorithm to train faster.\n",
    "- It reduces the complexity of a model and makes it easier to interpret.\n",
    "- It improves the accuracy of a model if the right subset is chosen.\n",
    "- It reduces overfitting.\n",
    "Next, we’ll discuss various methodologies and techniques that you can use to subset your feature space and help your models perform better and efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-florist",
   "metadata": {},
   "source": [
    "### Filter Method for Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-refrigerator",
   "metadata": {},
   "source": [
    "The filter method ranks each feature based on some uni-variate metric and then selects the highest-ranking features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-tobago",
   "metadata": {},
   "source": [
    "### Filter Selection Select independent features with: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-storm",
   "metadata": {},
   "source": [
    "- No constant Variables\n",
    "- No/less Quadi-constant variables\n",
    "- No Duplicate Rows\n",
    "- High correlation with the target variable\n",
    "- Low correlation with another independent variable\n",
    "- Higher information gain or mutual information of the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-closer",
   "metadata": {},
   "source": [
    "### Advantages of Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-leone",
   "metadata": {},
   "source": [
    "\n",
    "- Filter methods are model agnostic(compatible)\n",
    "- Rely entirely on features in the data set\n",
    "- Computationally very fast\n",
    "- Based on different statistical methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-serbia",
   "metadata": {},
   "source": [
    "### The disadvantage of Filter methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-stephen",
   "metadata": {},
   "source": [
    "The filter method looks at individual features for identifying it’s relative importance. A feature may not be useful on its own but may be an important influencer when combined with other features. Filter methods may miss such features.\n",
    "\n",
    "One thing that should be kept in mind is that the filter method does not remove multicollinearity. So, you must deal with the multicollinearity of features as well before training models for your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-threat",
   "metadata": {},
   "source": [
    "### Importing Dataset and Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "frequent-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 371)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(r\"Standard Customer Data.csv\", nrows=40000)    #Taking only 40K rows from the start\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-density",
   "metadata": {},
   "source": [
    "It is important to mention here that, in order to avoid overfitting, feature selection should only be applied to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-wagner",
   "metadata": {},
   "source": [
    "### Splitting Data Into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cooked-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y= train_test_split(data.drop(\"TARGET\",axis=1),data.TARGET,test_size=0.2,random_state=41)\n",
    "\n",
    "#Here, X = data.drop(\"TARGET\",axis=1), Y = data.Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-promotion",
   "metadata": {},
   "source": [
    "### Step:1 Removing Constant features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-anger",
   "metadata": {},
   "source": [
    "Constant features are the type of features that contain only one value for all the outputs in the dataset. Constant features provide no information that can help in classification of the record at hand. Therefore, it is advisable to remove all the constant features from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-associate",
   "metadata": {},
   "source": [
    "#### Removing Constant Features using VarianceThreshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-property",
   "metadata": {},
   "source": [
    "To remove constant features we will use VarianceThreshold function. The function requires a value for its threshold parameter. Passing a value of zero for the parameter will filter all the features with zero variance i.e constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "indonesian-graham",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 320)\n",
      "50\n",
      "ind_var2_0\n",
      "ind_var2\n",
      "ind_var18_0\n",
      "ind_var18\n",
      "ind_var27_0\n",
      "ind_var28_0\n",
      "ind_var28\n",
      "ind_var27\n",
      "ind_var34_0\n",
      "ind_var34\n",
      "ind_var41\n",
      "ind_var46_0\n",
      "ind_var46\n",
      "num_var18_0\n",
      "num_var18\n",
      "num_var27_0\n",
      "num_var28_0\n",
      "num_var28\n",
      "num_var27\n",
      "num_var34_0\n",
      "num_var34\n",
      "num_var41\n",
      "num_var46_0\n",
      "num_var46\n",
      "saldo_var18\n",
      "saldo_var28\n",
      "saldo_var27\n",
      "saldo_var34\n",
      "saldo_var41\n",
      "saldo_var46\n",
      "delta_imp_amort_var18_1y3\n",
      "delta_imp_amort_var34_1y3\n",
      "imp_amort_var18_hace3\n",
      "imp_amort_var18_ult1\n",
      "imp_amort_var34_hace3\n",
      "imp_amort_var34_ult1\n",
      "imp_reemb_var13_hace3\n",
      "imp_reemb_var17_hace3\n",
      "imp_reemb_var33_hace3\n",
      "imp_trasp_var17_out_hace3\n",
      "imp_trasp_var33_out_hace3\n",
      "num_var2_0_ult1\n",
      "num_var2_ult1\n",
      "num_reemb_var13_hace3\n",
      "num_reemb_var17_hace3\n",
      "num_reemb_var33_hace3\n",
      "num_trasp_var17_out_hace3\n",
      "num_trasp_var33_out_hace3\n",
      "saldo_var2_ult1\n",
      "saldo_medio_var13_medio_hace3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "constant_filter = VarianceThreshold(threshold=0)\n",
    "\n",
    "#Fitand transforming on train data\n",
    "data_constant = constant_filter.fit_transform(train_x)\n",
    "print(data_constant.shape)\n",
    "\n",
    "#Extracting all constant columns using get support function of our filter\n",
    "constant_columns = [column for column in train_x.columns\n",
    "                    if column not in train_x.columns[constant_filter.get_support()]]\n",
    "\n",
    "#No. of constant columns\n",
    "print(len(constant_columns))\n",
    "\n",
    "#Constant columns names:\n",
    "for column in constant_columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-document",
   "metadata": {},
   "source": [
    "#### Removing above identified constant columns from our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "thrown-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 321)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cons = data.drop(constant_columns,axis=1)\n",
    "data_cons.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-coordination",
   "metadata": {},
   "source": [
    "Earlier the length was 371. Now is 320. To see the constant columns names:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-rental",
   "metadata": {},
   "source": [
    "### Step 2: Removing Quasi-Constant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-newport",
   "metadata": {},
   "source": [
    "Quasi-constant features, as the name suggests, are the features that are almost constant. Such features are not very useful for making predictions. There is no rule as to what should be the threshold for the variance of quasi-constant features. \n",
    "\n",
    "However, as a rule of thumb, remove those quasi-constant features that have more than 99% similar values for the output observations.\n",
    "\n",
    "Thus, instead of passing 0 as the value for the threshold parameter, we will pass 0.01, which means that if the variance of the values in a column is less than 0.01, remove that column. In other words, remove feature column where approximately 99% of the values are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "practical-desire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32000, 265)\n",
      "105\n",
      "ind_var1\n",
      "ind_var2_0\n",
      "ind_var2\n",
      "ind_var6_0\n",
      "ind_var6\n",
      "ind_var13_largo\n",
      "ind_var13_medio_0\n",
      "ind_var13_medio\n",
      "ind_var14\n",
      "ind_var17_0\n",
      "ind_var17\n",
      "ind_var18_0\n",
      "ind_var18\n",
      "ind_var19\n",
      "ind_var20_0\n",
      "ind_var20\n",
      "ind_var27_0\n",
      "ind_var28_0\n",
      "ind_var28\n",
      "ind_var27\n",
      "ind_var29_0\n",
      "ind_var29\n",
      "ind_var30_0\n",
      "ind_var31_0\n",
      "ind_var31\n",
      "ind_var32_cte\n",
      "ind_var32_0\n",
      "ind_var32\n",
      "ind_var33_0\n",
      "ind_var33\n",
      "ind_var34_0\n",
      "ind_var34\n",
      "ind_var40\n",
      "ind_var41\n",
      "ind_var39\n",
      "ind_var44_0\n",
      "ind_var44\n",
      "ind_var46_0\n",
      "ind_var46\n",
      "num_var6_0\n",
      "num_var6\n",
      "num_var13_medio_0\n",
      "num_var13_medio\n",
      "num_var18_0\n",
      "num_var18\n",
      "num_op_var40_hace3\n",
      "num_var27_0\n",
      "num_var28_0\n",
      "num_var28\n",
      "num_var27\n",
      "num_var29_0\n",
      "num_var29\n",
      "num_var34_0\n",
      "num_var34\n",
      "num_var41\n",
      "num_var46_0\n",
      "num_var46\n",
      "saldo_var18\n",
      "saldo_var28\n",
      "saldo_var27\n",
      "saldo_var34\n",
      "saldo_var41\n",
      "saldo_var46\n",
      "delta_imp_amort_var18_1y3\n",
      "delta_imp_amort_var34_1y3\n",
      "delta_imp_aport_var33_1y3\n",
      "delta_num_aport_var33_1y3\n",
      "imp_amort_var18_hace3\n",
      "imp_amort_var18_ult1\n",
      "imp_amort_var34_hace3\n",
      "imp_amort_var34_ult1\n",
      "imp_reemb_var13_hace3\n",
      "imp_reemb_var17_hace3\n",
      "imp_reemb_var33_hace3\n",
      "imp_trasp_var17_out_hace3\n",
      "imp_trasp_var33_out_hace3\n",
      "ind_var7_emit_ult1\n",
      "ind_var7_recib_ult1\n",
      "num_var2_0_ult1\n",
      "num_var2_ult1\n",
      "num_aport_var33_hace3\n",
      "num_aport_var33_ult1\n",
      "num_var7_emit_ult1\n",
      "num_meses_var13_medio_ult3\n",
      "num_meses_var17_ult3\n",
      "num_meses_var29_ult3\n",
      "num_meses_var33_ult3\n",
      "num_meses_var44_ult3\n",
      "num_reemb_var13_hace3\n",
      "num_reemb_var13_ult1\n",
      "num_reemb_var17_hace3\n",
      "num_reemb_var17_ult1\n",
      "num_reemb_var33_hace3\n",
      "num_reemb_var33_ult1\n",
      "num_trasp_var17_in_hace3\n",
      "num_trasp_var17_in_ult1\n",
      "num_trasp_var17_out_hace3\n",
      "num_trasp_var17_out_ult1\n",
      "num_trasp_var33_in_hace3\n",
      "num_trasp_var33_in_ult1\n",
      "num_trasp_var33_out_hace3\n",
      "num_trasp_var33_out_ult1\n",
      "num_venta_var44_hace3\n",
      "saldo_var2_ult1\n",
      "saldo_medio_var13_medio_hace3\n"
     ]
    }
   ],
   "source": [
    "qcons_filter = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "#Fitand transforming on train data\n",
    "data_qcons = qcons_filter.fit_transform(train_x)\n",
    "print(data_qcons.shape)\n",
    "\n",
    "#Extracting all Quasi constant columns using get support function of our filter\n",
    "qcons_columns = [column for column in train_x.columns\n",
    "                    if column not in train_x.columns[qcons_filter.get_support()]]\n",
    "\n",
    "#No. of Quasi constant columns\n",
    "print(len(qcons_columns))\n",
    "\n",
    "#Quasi Constant columns names:\n",
    "for column in qcons_columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-palmer",
   "metadata": {},
   "source": [
    "We got 105 Quasi constant. Earlier we got 50 when variance was 0. This si surely a better result. The threshold ro be kept depends on us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-bulletin",
   "metadata": {},
   "source": [
    "#### Removing above identified quasi constant columns from our database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "vocal-belly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 266)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qcons = data.drop(qcons_columns,axis=1)\n",
    "data_qcons.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-editing",
   "metadata": {},
   "source": [
    "the remaining shape of our data is , we have 266 columns left now!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-anxiety",
   "metadata": {},
   "source": [
    "### Step 3 Removing Duplicate Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-platinum",
   "metadata": {},
   "source": [
    "Duplicate features are the features that have similar values. Duplicate features do not add any value to algorithm training, rather they add overhead and unnecessary delay to the training time. Therefore, it is always recommended to remove the duplicate features from the dataset before training.\n",
    "\n",
    "For constant and quasi-constant features, we have no built-in Python method that can remove duplicate features. However, we have a method that can help us identify duplicate rows in a pandas dataframe. Using that by transposing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-wealth",
   "metadata": {},
   "source": [
    "#### Transposing our \"quasi-constant\" modified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "absolute-cyprus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 40000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_qcons_t = data_qcons.T\n",
    "data_qcons_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-hands",
   "metadata": {},
   "source": [
    "Now, that our columns have taken the place of row, we can find the duplicacy in columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "average-found",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "print(data_qcons_t.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-flour",
   "metadata": {},
   "source": [
    "Thus, even after removing quasi-constant columns, we have 21 more columns to be removed that are duplicated.\n",
    "\n",
    "Finally, we can drop the duplicate rows using the drop_duplicates() method. If you pass the string value first to the keep parameter of the drop_duplicates() method, all the duplicate rows will be dropped except the first copy. We will then ranspose back our new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-rugby",
   "metadata": {},
   "source": [
    "#### Dropping Duplicated method using drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "protecting-surge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 245)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cons_dup = data_qcons_t.drop_duplicates(keep='first').T\n",
    "data_cons_dup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-newton",
   "metadata": {},
   "source": [
    "We got a better refined training set with 245 columns now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-offset",
   "metadata": {},
   "source": [
    "### Step: 4 Correlation of Features with the Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-japanese",
   "metadata": {},
   "source": [
    "In addition to the duplicate features, a dataset can also contain correlated features. Identify input features having a high correlation with the target variable.Here we print the correlation of each of the input feature with the target variable.\n",
    "\n",
    "As this database has columns that has very low correlations, we will use some other database for calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-humanitarian",
   "metadata": {},
   "source": [
    "#### Importing and Processing Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "patient-drain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'model_year', 'origin', 'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardata = pd.read_csv(\"mpg.csv\")\n",
    "cardata.dropna()\n",
    "cardata.shape\n",
    "cardata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "impressed-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cardata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-produce",
   "metadata": {},
   "source": [
    "#### Handling categorical variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-integer",
   "metadata": {},
   "source": [
    "There are 3 categorical variables as can be said by seeing dtype of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "offensive-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating the horsepower feature to int\n",
    "cardata[\"horsepower\"]= pd.to_numeric(cardata[\"horsepower\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-newman",
   "metadata": {},
   "source": [
    "We see that horsepower is no more a categorical variable and Car name is the only categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "favorite-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding:\n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X_en= cardata.iloc[:, 8].values\n",
    "X_en = labelencoder.fit_transform(X_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "automatic-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardata = cardata.drop([\"name\",\"origin\"],axis=1)\n",
    "cardata[\"name\"] = X_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-comparison",
   "metadata": {},
   "source": [
    "#### Creating the input features X and target variable y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "respective-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cylinders  displacement  horsepower  weight  acceleration  model_year  name\n",
       "0          8         307.0       130.0    3504          12.0          70    49\n",
       "1          8         350.0       165.0    3693          11.5          70    36"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= cardata[\"mpg\"]\n",
    "X = cardata.iloc[:,1:8]\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "graphic-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18.0\n",
       "1    15.0\n",
       "Name: mpg, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "atmospheric-crystal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cylinders  displacement  horsepower  weight  acceleration  model_year  \\\n",
      "0          8         307.0       130.0    3504          12.0          70   \n",
      "1          8         350.0       165.0    3693          11.5          70   \n",
      "\n",
      "   name   mpg  \n",
      "0    49  18.0  \n",
      "1    36  15.0  \n"
     ]
    }
   ],
   "source": [
    "#Create a data set copy with all the input features after converting them to numeric including target variable\n",
    "full_data= X.copy()\n",
    "full_data[\"mpg\"]= y\n",
    "print(full_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-summer",
   "metadata": {},
   "source": [
    "#### Finding correlation with target variable of independent predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "furnished-columbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders      -0.775396\n",
      "displacement   -0.804203\n",
      "horsepower     -0.778427\n",
      "weight         -0.831741\n",
      "acceleration    0.420289\n",
      "model_year      0.579267\n",
      "name            0.273936\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "imp = full_data.drop(\"mpg\", axis=1).apply(lambda x: x.corr(full_data.mpg))\n",
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "public-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders       3\n",
      "displacement    1\n",
      "horsepower      2\n",
      "weight          0\n",
      "acceleration    6\n",
      "model_year      4\n",
      "name            5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(imp)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "textile-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight         -0.831741\n",
      "displacement   -0.804203\n",
      "horsepower     -0.778427\n",
      "cylinders      -0.775396\n",
      "name            0.273936\n",
      "acceleration    0.420289\n",
      "model_year      0.579267\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(imp[indices])     #Sorted in ascending order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-notion",
   "metadata": {},
   "source": [
    "#### Plotting for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "manufactured-pointer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names=['cylinders','displacement','horsepower','weight','acceleration','model year', 'name']\n",
    "plt.title('Miles Per Gallon')\n",
    "\n",
    "#Plotting horizontal bar graph\n",
    "plt.barh(range(len(indices)), imp[indices], color='g', align='center')\n",
    "plt.yticks(range(len(indices)), [names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-denver",
   "metadata": {},
   "source": [
    "Shown above is the correlation of each feature with our target variable(TARGET).We want to keep features with only a high correlation with the target variable. This implies that the input feature has a high influence in predicting the target variable.\n",
    "\n",
    "We set the threshold to the absolute value of 0.4. We keep input features only if the correlation of the input feature with the target variable is greater than 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-coordination",
   "metadata": {},
   "source": [
    "The correlation threshold value to determine highly collinear variables should be ± 0.50 or near that. Will take absolute value as both negative and positive correlation matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "pleasant-solomon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders\n",
      "displacement\n",
      "horsepower\n",
      "weight\n",
      "acceleration\n",
      "model year\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(indices)):\n",
    "    if np.abs(imp[i])>0.4:\n",
    "        print(names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-deputy",
   "metadata": {},
   "source": [
    "That is car name can be dropped from our dataset as per our observations from predictors relationship with target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "perfect-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(\"name\",axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-second",
   "metadata": {},
   "source": [
    "### Step 5: Correlation with Other Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-milwaukee",
   "metadata": {},
   "source": [
    "Identify input features that have a low correlation with other independent variables.\n",
    "Iterating through all the filtered input features based on step 1 and checking each input feature correlation with all other input features.\n",
    "We will keep input features that are not highly correlated with other input features``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "taken-telescope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cylinders  is highly  correlated  with  displacement\n",
      "cylinders  is highly  correlated  with  horsepower\n",
      "cylinders  is highly  correlated  with  weight\n",
      "cylinders  is not correlated  with  name\n",
      "displacement  is highly  correlated  with  cylinders\n",
      "displacement  is highly  correlated  with  horsepower\n",
      "displacement  is highly  correlated  with  weight\n",
      "displacement  is not correlated  with  name\n",
      "horsepower  is highly  correlated  with  cylinders\n",
      "horsepower  is highly  correlated  with  displacement\n",
      "horsepower  is highly  correlated  with  weight\n",
      "horsepower  is not correlated  with  name\n",
      "weight  is highly  correlated  with  cylinders\n",
      "weight  is highly  correlated  with  displacement\n",
      "weight  is highly  correlated  with  horsepower\n",
      "weight  is not correlated  with  name\n",
      "acceleration  is not correlated  with  model_year\n",
      "acceleration  is not correlated  with  name\n",
      "model_year  is not correlated  with  acceleration\n",
      "model_year  is not correlated  with  name\n",
      "name  is not correlated  with  cylinders\n",
      "name  is not correlated  with  displacement\n",
      "name  is not correlated  with  horsepower\n",
      "name  is not correlated  with  weight\n",
      "name  is not correlated  with  acceleration\n",
      "name  is not correlated  with  model_year\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(X.columns)):\n",
    "    for j in  range(0,len(X.columns)):\n",
    "        if i!=j:\n",
    "            corr_1=np.abs(X[X.columns[i]].corr(X[X.columns[j]]))\n",
    "            if corr_1 <0.3:\n",
    "                print( X.columns[i] , \" is not correlated  with \", X.columns[j])\n",
    "            elif corr_1>0.75:\n",
    "                print( X.columns[i] , \" is highly  correlated  with \", X.columns[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-dispute",
   "metadata": {},
   "source": [
    "displacement, horsepower, cylinder, and weight are highly correlated. We will keep only keep one of them.Based on the above result we keep cylinders, acceleration and model year and remove horsepower, displacement, and weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "mobile-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X.drop([\"cylinders\",\"weight\",\"displacement\"],axis=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-secondary",
   "metadata": {},
   "source": [
    "In case of Dataset with large no. of input variable we can use pearson's or Spearman's coefficient to calculate correlational variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-cooperative",
   "metadata": {},
   "source": [
    "### Step:6 Finding Mutual Information or Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-teens",
   "metadata": {},
   "source": [
    "As per the wikipedia,In probability theory and information theory, the mutual information (MI) of two random variables is a measure of the mutual dependence between the two variables. More specifically, it quantifies the \"amount of information\" obtained about one random variable through observing the other random variable. \n",
    "\n",
    "As per Sklearn documentation, Mutual information (MI)between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency.\n",
    "\n",
    "We will find the information gain or mutual information of the independent variable with respect to a target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "alert-portable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   horsepower    392 non-null    float64\n",
      " 1   acceleration  398 non-null    float64\n",
      " 2   model_year    398 non-null    int64  \n",
      " 3   name          398 non-null    int32  \n",
      "dtypes: float64(2), int32(1), int64(1)\n",
      "memory usage: 11.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(398, 4)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.info()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "funky-palace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398,)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "smart-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_regression\n",
    "# mi = mutual_info_regression(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-relevance",
   "metadata": {},
   "source": [
    "Return : Estimated mutual information between each feature and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "orange-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the mutual information\n",
    "\n",
    "# mi = pd.Series(mi)\n",
    "# mi.index = X.columns\n",
    "# mi.sort_values(ascending=False)\n",
    "# mi.sort_values(ascending=False).plot.bar(figsize=(10, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-sandwich",
   "metadata": {},
   "source": [
    "We now have our feature importance to predict the miles per gallon. Miles per gallon can be predicted based on the number of cylinders in the car, the year car was manufactured ad the acceleration. \n",
    "\n",
    "Filter method for feature selection is thus model agnostic, simple, and easy to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-exploration",
   "metadata": {},
   "source": [
    "References:\n",
    "1. https://stackabuse.com/applying-filter-methods-in-python-for-feature-selection\n",
    "2. https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/\n",
    "3. https://towardsdatascience.com/feature-selection-in-python-using-filter-method-7ae5cbc4ee05\n",
    "4. http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html\n",
    "5. https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-monitoring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
